import pyro, numpy as np, torch, pyro.distributions   as dist, torch.nn as nn
from pyro.optim import Adam
import torch.distributions.constraints as constraints
from pyro.infer import SVI
if pyro.__version__ > '0.1.2': from pyro.infer import Trace_ELBO
from pyro.contrib.autoguide import *
import math
def amb(x):
    return x.data.numpy().tolist() if isinstance(x, torch.Tensor) else x
n_eth=4
n_eth=torch.tensor(n_eth)
age= np.array([2, 3, 1, 2, 1, 2, 2, 1, 1, 1, 1, 3, 2, 3, 1, 2, 3, 2, 3, 1, 1, 2, 2, 2, 3, 2, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 2, 2, 1, 1, 1, 3, 3, 1, 1, 1, 2, 3, 2, 3, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 3, 3, 2, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 3, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 1, 1, 3, 2, 2, 3, 2, 3, 1, 1, 1, 1, 2, 1, 2, 1, 1, 3, 2, 2, 2, 2, 1, 3, 1, 1, 3, 2, 2, 2, 3, 2, 2, 3, 3, 2, 1, 3, 2, 2, 2, 3, 2, 2, 2, 2, 1, 2, 1, 2, 3, 2, 2, 2, 3, 3, 3, 1, 3, 1, 3, 1, 1, 2, 2, 2, 1, 1, 2, 3, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 3, 2, 3, 2, 1, 2, 3, 1, 3, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 3, 3, 2, 3, 2, 1, 2, 1, 1, 2, 3, 1, 1, 1, 3, 1, 3, 1, 2, 3, 2, 2, 2, 2, 2, 3, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 3, 2, 3, 1, 3, 1, 2, 2, 1, 3, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 3, 2, 1, 1, 3, 3, 1, 2, 2, 3, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 3, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 3, 2, 2, 1, 2, 1, 1, 1, 3, 2, 1, 3, 2, 3, 1, 2, 3, 1, 2, 1, 2, 2, 3, 2, 3, 3, 2, 1, 1, 1, 3, 1, 2, 2, 2, 1, 1, 3, 2, 2, 1, 2, 2, 2, 3, 1, 1, 2, 1, 1, 1, 2, 1, 3, 2, 2, 1, 1, 2, 1, 1, 1, 3, 2, 2, 3, 2, 2, 1, 1, 1, 2, 3, 1, 2, 1, 1, 1, 1, 2, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 3, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 3, 3, 1, 1, 2, 2, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 3, 1, 2, 3, 2, 3, 2, 2, 2, 3, 3, 1, 1, 2, 3, 1, 2, 2, 2, 1, 1, 2, 3, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 3, 2, 2, 1, 1, 3, 2, 2, 3, 1, 1, 1, 1, 2, 2, 2, 3, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 3, 2, 2, 2, 1, 3, 3, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 3, 2, 2, 2, 1, 1, 2, 3, 1, 3, 3, 1, 1, 2, 1, 3, 1, 1, 1, 1, 3, 2, 2, 3, 2, 3, 1, 1, 3, 1, 2, 1, 1, 2, 1, 1, 2, 2, 3, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 2, 3, 3, 1, 1, 1, 1, 2, 1, 2, 3, 1, 2, 2, 1, 3, 2, 1, 3, 2, 1, 3, 1, 2, 3, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 3, 1, 1, 1, 2, 2, 1, 2, 3, 2, 1, 2, 1, 2, 1, 1, 1, 1, 3, 2, 3, 2, 2, 1, 2, 3, 2, 1, 3, 2, 1, 2, 2, 3, 1, 2, 1, 1, 1, 2, 2, 2, 3, 3, 1, 1, 1, 3, 2, 1, 2, 1, 1, 3, 2, 1, 2, 2, 2, 2, 1, 3, 3, 3, 2, 3, 2, 1, 3, 3, 1, 1, 3, 2, 3, 1, 1, 1, 2, 3, 2, 2, 2, 1, 1, 1, 3, 1, 3, 2, 3, 3, 1, 2, 2, 3, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 3, 3, 2, 3, 1, 1, 3, 2, 2, 2, 1, 2, 1, 3, 3, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 3, 2, 1, 2, 1, 3, 1, 1, 3, 2, 1, 2, 2, 1, 1, 2, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 1, 2, 1, 2, 3, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 3, 3, 1, 2, 2, 3, 2, 2, 2, 3, 1, 3, 3, 3, 3, 2, 1, 2, 1, 1, 2, 2, 1, 3, 1, 2, 1, 3, 2, 3, 3, 1, 1, 2, 1, 1, 2, 2, 1, 3, 2, 1, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 3, 1, 3, 2, 1, 3, 2, 1, 1, 1, 1, 3, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 3, 3, 2, 2, 3, 1, 3, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 2, 1, 1, 2, 3, 2, 3, 2, 1, 1, 1, 2, 2, 2, 2, 1, 3, 1, 1, 2, 1, 2, 3, 2, 1, 1, 3, 1], dtype=np.int64).reshape(1059,1)
age=torch.tensor(age)
N=1059
N=torch.tensor(N)
n_age=3
n_age=torch.tensor(n_age)
y= np.array([10.8197782844, 11.0020998412, 10.3089526606, 10.8395809117, 9.10497985632, 10.275051109, 10.3734911818, 7.60090245954, 10.203592145, 10.3089526606, 9.39266192877, 9.39266192877, 9.99879773234, 9.74096862304, 10.5966347331, 10.6919449129, 8.85366542804, 10.8780471925, 8.51719319142, 9.5468126086, 8.61250337122, 10.5966347331, 10.4341158036, 9.21034037198, 10.203592145, 10.8197782844, 10.6213273457, 9.61580548008, 10.1266311039, 11.2252433925, 10.203592145, 9.39266192877, 10.3089526606, 9.95227771671, 10.203592145, 10.1266311039, 10.0858091093, 10.3734911818, 9.21034037198, 9.30565055178, 9.83627880284, 9.90348755254, 8.16051824748, 9.47270463644, 9.95227771671, 10.4341158036, 9.74096862304, 10.4631033405, 8.2940496401, 9.5468126086, 9.21034037198, 10.1266311039, 9.68034400122, 9.68034400122, 9.71111565989, 8.25322764558, 9.99879773234, 5.29831736655, 10.165851817, 7.82404601086, 9.74096862304, 8.98719682066, 9.21034037198, 9.61580548008, 7.78322401634, 10.3089526606, 10.3089526606, 9.21034037198, 8.51719319142, 9.39266192877, 9.90348755254, 9.90348755254, 9.90348755254, 7.09007683578, 6.55108033504, 9.90348755254, 9.21034037198, 10.5966347331, 11.0020998412, 9.68284088142, 9.61580548008, 9.21034037198, 10.4042628404, 9.79812703688, 9.61580548008, 9.95227771671, 9.95227771671, 10.5186731916, 10.5453414387, 9.74096862304, 10.3734911818, 10.2219412837, 9.71111565989, 10.1266311039, 10.203592145, 8.51719319142, 11.156250521, 8.51719319142, 8.51719319142, 9.90348755254, 8.2940496401, 11.0020998412, 8.51719319142, 10.3089526606, 11.156250521, 10.8197782844, 10.6919449129, 10.3089526606, 9.21034037198, 10.0432494949, 10.7144177688, 9.61580548008, 9.74096862304, 10.3089526606, 10.2219412837, 9.79812703688, 10.6689553947, 10.3734911818, 9.21034037198, 11.0020998412, 9.95227771671, 7.78322401634, 6.90775527898, 10.203592145, 8.79482492801, 9.68034400122, 11.4075649493, 8.98719682066, 9.90348755254, 9.61580548008, 9.39266192877, 10.0858091093, 9.90348755254, 9.85219425815, 9.21034037198, 10.5966347331, 10.1266311039, 10.1266311039, 10.1266311039, 9.85219425815, 10.6919449129, 9.61580548008, 9.74096862304, 10.0858091093, 10.0432494949, 11.0821425489, 8.85366542804, 10.5966347331, 9.61580548008, 9.90348755254, 9.90348755254, 9.90348755254, 10.1266311039, 10.7995755771, 9.30565055178, 9.68034400122, 10.4631033405, 11.7360690163, 10.0432494949, 9.74096862304, 10.203592145, 11.156250521, 10.4631033405, 9.21034037198, 10.4631033405, 9.61580548008, 9.39266192877, 8.98719682066, 10.4631033405, 10.7144177688, 9.61580548008, 10.0858091093, 10.1266311039, 10.1266311039, 9.90348755254, 10.0858091093, 10.6919449129, 11.1418617836, 11.034889664, 10.3734911818, 9.90348755254, 10.3734911818, 10.1266311039, 12.043553716, 10.4631033405, 10.5966347331, 10.4042628404, 9.79812703688, 10.3089526606, 10.165851817, 8.51719319142, 9.74096862304, 10.3734911818, 9.61580548008, 10.8197782844, 8.98719682066, 10.5966347331, 10.5966347331, 10.3966582411, 10.4912742174, 8.69951474821, 9.39266192877, 11.0020998412, 10.5966347331, 10.6689553947, 10.7144177688, 8.69951474821, 9.90348755254, 9.74096862304, 7.60090245954, 11.0821425489, 10.8197782844, 9.30565055178, 10.4631033405, 10.203592145, 8.16051824748, 10.6454248973, 9.90348755254, 9.61580548008, 9.21034037198, 9.74096862304, 10.2399597892, 9.61580548008, 9.90348755254, 9.90348755254, 9.25913053615, 9.47270463644, 9.21034037198, 8.00636756765, 10.0858091093, 9.74096862304, 9.30565055178, 10.3734911818, 9.74096862304, 8.00636756765, 7.64969262371, 8.06840295857, 9.74096862304, 10.3089526606, 9.61580548008, 10.0858091093, 10.8197782844, 10.8197782844, 9.90348755254, 10.3089526606, 9.99879773234, 10.203592145, 8.2940496401, 9.76995615991, 9.71111565989, 10.2399597892, 10.8589989976, 9.61580548008, 9.85219425815, 10.203592145, 9.61580548008, 9.61580548008, 9.58190392841, 10.0858091093, 9.79812703688, 8.2940496401, 6.55108033504, 10.203592145, 9.39266192877, 9.99879773234, 10.3089526606, 10.4631033405, 9.90348755254, 10.3734911818, 8.69951474821, 9.39266192877, 9.21034037198, 6.90775527898, 9.68034400122, 10.1266311039, 10.1266311039, 10.3734911818, 10.4631033405, 8.69951474821, 11.2897819137, 9.90348755254, 6.90775527898, 10.2399597892, 10.165851817, 10.203592145, 9.79812703688, 7.60090245954, 8.69951474821, 10.1266311039, 9.39266192877, 9.39266192877, 8.2940496401, 10.165851817, 10.0432494949, 9.95227771671, 10.1266311039, 8.2940496401, 10.0816337379, 10.4631033405, 10.165851817, 10.1266311039, 10.0647557001, 9.39266192877, 9.61580548008, 8.00636756765, 9.61580548008, 12.0725412529, 6.90775527898, 9.21034037198, 9.90348755254, 10.4631033405, 10.5966347331, 10.8197782844, 11.512925465, 10.4631033405, 10.0858091093, 10.4631033405, 10.3089526606, 8.51719319142, 11.9049675527, 10.3089526606, 8.77955745588, 8.00636756765, 10.5966347331, 10.3089526606, 9.5468126086, 9.61580548008, 10.165851817, 8.98719682066, 10.0858091093, 9.21034037198, 9.39266192877, 10.8197782844, 10.0432494949, 10.5966347331, 8.69951474821, 8.51719319142, 11.6082356448, 10.6213273457, 9.95227771671, 8.2940496401, 10.1266311039, 10.3089526606, 9.5468126086, 8.69951474821, 9.5468126086, 10.6689553947, 10.1266311039, 11.0821425489, 9.68034400122, 9.90348755254, 9.39266192877, 8.98719682066, 9.68034400122, 9.85219425815, 9.95227771671, 10.6689553947, 10.4631033405, 9.95227771671, 8.66561319653, 9.74096862304, 10.0858091093, 9.30565055178, 9.21034037198, 10.5966347331, 10.5966347331, 10.0858091093, 10.0858091093, 9.90348755254, 11.0020998412, 9.30565055178, 8.51719319142, 10.203592145, 11.3963916487, 10.5966347331, 9.61580548008, 6.90775527898, 9.99879773234, 9.39266192877, 9.99879773234, 10.5966347331, 10.5966347331, 10.4631033405, 8.85366542804, 9.5468126086, 9.61580548008, 8.69951474821, 9.30565055178, 9.21034037198, 9.90348755254, 10.5453414387, 10.275051109, 9.90348755254, 8.98719682066, 10.4912742174, 7.31322038709, 10.6454248973, 10.1266311039, 9.47270463644, 10.3089526606, 8.85366542804, 10.3417424835, 9.61580548008, 10.8197782844, 8.51719319142, 6.39692965522, 9.5468126086, 10.5966347331, 10.0858091093, 9.99879773234, 9.90348755254, 9.90907193083, 10.6213273457, 9.47270463644, 11.0020998412, 10.0858091093, 10.5453414387, 8.00636756765, 9.47270463644, 8.51719319142, 9.90348755254, 9.99879773234, 10.2399597892, 9.99879773234, 10.3089526606, 10.3089526606, 10.3089526606, 10.165851817, 9.99879773234, 10.1266311039, 9.30565055178, 9.47270463644, 9.21034037198, 9.39266192877, 8.85366542804, 10.9508065468, 10.4912742174, 10.275051109, 8.98719682066, 8.00636756765, 9.90348755254, 10.4042628404, 9.68034400122, 8.98719682066, 10.3734911818, 9.58190392841, 9.47270463644, 8.85366542804, 9.39266192877, 9.85219425815, 9.10497985632, 9.90348755254, 10.9150884642, 9.21034037198, 9.47270463644, 9.90348755254, 10.3089526606, 9.39266192877, 10.165851817, 9.43348392329, 8.98719682066, 9.61580548008, 11.0821425489, 10.1266311039, 8.98719682066, 9.61580548008, 9.39266192877, 10.4631033405, 10.5966347331, 10.275051109, 9.61580548008, 9.90348755254, 8.00636756765, 6.90775527898, 8.98719682066, 8.51719319142, 10.1266311039, 9.90348755254, 10.3089526606, 9.39266192877, 9.21034037198, 9.68034400122, 10.7144177688, 10.5966347331, 9.85219425815, 9.77565418103, 10.3089526606, 9.79812703688, 10.1266311039, 8.69951474821, 11.156250521, 9.61580548008, 10.1266311039, 10.4631033405, 9.79812703688, 10.2399597892, 9.61580548008, 9.99879773234, 10.4631033405, 9.79812703688, 10.4631033405, 9.70503661381, 9.99879773234, 10.3089526606, 9.74096862304, 10.1266311039, 9.21034037198, 10.5966347331, 9.43348392329, 10.4631033405, 11.5617156291, 11.512925465, 9.95227771671, 9.21034037198, 10.4042628404, 10.165851817, 9.79812703688, 9.61580548008, 8.51719319142, 11.0020998412, 10.2399597892, 10.6454248973, 7.60090245954, 9.90348755254, 10.2399597892, 9.21034037198, 10.3417424835, 9.74096862304, 9.68034400122, 10.4631033405, 8.00636756765, 9.68034400122, 10.4631033405, 10.203592145, 10.1266311039, 10.5966347331, 10.7144177688, 9.5468126086, 10.1266311039, 10.5966347331, 10.4341158036, 10.5966347331, 10.4631033405, 9.39266192877, 10.3089526606, 10.0432494949, 7.60090245954, 9.90348755254, 9.21034037198, 11.0020998412, 9.39266192877, 10.1266311039, 8.98719682066, 7.60090245954, 9.8309168597, 9.90348755254, 11.512925465, 10.8197782844, 10.203592145, 6.90775527898, 9.79812703688, 9.74096862304, 9.5468126086, 10.4042628404, 10.0432494949, 9.21034037198, 9.99879773234, 9.47270463644, 10.4042628404, 10.4912742174, 9.21034037198, 8.69951474821, 9.39266192877, 9.21034037198, 9.95227771671, 10.165851817, 9.99879773234, 10.0432494949, 9.90348755254, 9.21034037198, 8.85366542804, 9.61580548008, 10.165851817, 9.21034037198, 8.00636756765, 10.203592145, 10.2399597892, 9.61580548008, 10.9150884642, 9.90348755254, 9.04782144248, 10.3089526606, 9.90348755254, 10.1266311039, 8.00636756765, 9.68034400122, 9.21034037198, 9.61580548008, 10.2399597892, 10.3577428248, 11.4616321706, 10.5453414387, 10.3089526606, 10.4884925745, 9.39266192877, 9.21034037198, 10.7144177688, 10.5966347331, 9.97580821412, 9.5468126086, 10.5453414387, 6.90775527898, 9.61580548008, 10.0858091093, 8.41183267576, 9.79812703688, 9.5468126086, 9.21034037198, 9.15904707759, 8.69951474821, 7.82404601086, 10.5966347331, 10.1266311039, 10.2399597892, 10.4042628404, 8.2940496401, 8.31874225269, 10.3734911818, 9.47270463644, 8.98719682066, 9.74096862304, 9.79812703688, 9.39266192877, 8.85366542804, 7.09007683578, 9.5468126086, 9.74096862304, 10.3089526606, 10.1266311039, 9.99879773234, 9.61580548008, 9.90348755254, 9.10497985632, 9.74096862304, 7.49554194388, 9.79812703688, 10.1266311039, 9.90348755254, 11.2252433925, 8.16051824748, 10.3089526606, 6.90775527898, 9.10497985632, 9.30565055178, 9.39266192877, 10.3089526606, 9.85219425815, 9.10497985632, 10.3089526606, 9.10497985632, 9.61580548008, 8.98719682066, 10.4042628404, 9.39266192877, 9.79812703688, 10.3089526606, 9.43348392329, 9.21034037198, 9.95227771671, 9.95227771671, 8.51719319142, 9.99879773234, 10.3089526606, 11.7199396344, 8.98719682066, 7.60090245954, 8.93590352627, 9.21034037198, 10.4631033405, 9.61580548008, 8.2940496401, 9.68034400122, 5.29831736655, 10.0432494949, 9.68034400122, 8.69951474821, 6.39692965522, 10.2399597892, 9.61580548008, 9.61580548008, 10.1266311039, 9.61580548008, 10.5966347331, 10.3089526606, 8.51719319142, 10.4631033405, 9.68034400122, 10.2399597892, 9.90348755254, 9.95227771671, 9.74096862304, 10.0858091093, 10.5966347331, 8.98719682066, 9.85219425815, 8.51719319142, 10.0858091093, 8.51719319142, 10.4042628404, 10.0858091093, 8.69951474821, 11.4075649493, 10.9508065468, 9.53242387115, 10.3089526606, 9.61580548008, 10.3417424835, 10.4042628404, 10.3089526606, 9.39266192877, 8.51719319142, 9.95227771671, 10.2399597892, 9.39266192877, 9.85219425815, 8.69951474821, 8.57546209954, 9.61580548008, 9.74096862304, 7.43838353004, 8.59415423255, 9.21034037198, 10.4631033405, 10.2399597892, 10.6454248973, 10.7144177688, 10.9150884642, 10.4912742174, 10.1266311039, 9.85219425815, 10.5453414387, 9.61580548008, 11.4721034704, 9.30565055178, 9.10497985632, 8.51719319142, 10.8197782844, 8.69951474821, 11.512925465, 9.71111565989, 10.3734911818, 10.3089526606, 9.21034037198, 9.61580548008, 10.165851817, 9.74096862304, 9.99879773234, 9.21034037198, 10.8197782844, 9.90348755254, 5.99146454711, 9.68034400122, 9.5468126086, 8.51719319142, 10.5966347331, 8.51719319142, 10.1266311039, 9.39266192877, 10.9681982895, 9.79812703688, 6.90775527898, 9.95227771671, 9.30565055178, 9.47270463644, 10.1266311039, 6.39692965522, 10.1266311039, 10.4912742174, 9.61580548008, 8.16051824748, 9.85245738142, 11.034889664, 10.1266311039, 10.8197782844, 10.5966347331, 10.165851817, 9.99879773234, 9.95227771671, 10.3089526606, 10.203592145, 8.2940496401, 10.7144177688, 9.79812703688, 8.69951474821, 9.5468126086, 10.4631033405, 9.61580548008, 9.39266192877, 6.90775527898, 10.3734911818, 7.31322038709, 8.00636756765, 10.4631033405, 11.156250521, 9.95227771671, 10.8197782844, 9.61580548008, 9.10497985632, 9.21034037198, 10.3089526606, 9.68034400122, 9.90348755254, 11.512925465, 9.21034037198, 10.4631033405, 8.85366542804, 8.98719682066, 9.30565055178, 10.1266311039, 10.1266311039, 10.3089526606, 10.7789562899, 9.74096862304, 10.165851817, 9.21034037198, 11.0020998412, 9.99879773234, 10.0858091093, 9.90348755254, 8.85366542804, 10.3089526606, 10.0432494949, 9.90348755254, 8.00636756765, 10.3089526606, 9.39266192877, 10.5966347331, 9.61580548008, 10.4912742174, 9.21034037198, 9.47270463644, 9.21034037198, 10.3089526606, 10.0432494949, 10.2399597892, 9.90348755254, 10.1266311039, 10.1266311039, 9.79812703688, 9.68034400122, 10.7144177688, 9.39266192877, 7.60090245954, 9.21034037198, 9.5468126086, 9.61580548008, 9.21034037198, 7.09007683578, 9.61580548008, 9.21034037198, 7.60090245954, 8.2940496401, 9.21034037198, 7.31322038709, 9.79812703688, 8.2940496401, 10.2399597892, 9.21034037198, 8.00636756765, 9.39266192877, 9.85219425815, 10.4912742174, 8.85366542804, 10.4631033405, 10.5966347331, 9.61580548008, 8.98719682066, 10.1266311039, 10.2399597892, 9.99879773234, 9.97580821412, 8.00636756765, 10.0432494949, 9.68034400122, 9.61580548008, 10.8780471925, 10.165851817, 8.2940496401, 9.21034037198, 10.6689553947, 9.74096862304, 8.2940496401, 10.8197782844, 10.9150884642, 10.2399597892, 8.51719319142, 9.79812703688, 9.95227771671, 9.39266192877, 10.4042628404, 10.8197782844, 9.68034400122, 10.4631033405, 10.1266311039, 9.90348755254, 9.79812703688, 10.1266311039, 10.5966347331, 9.5468126086, 9.39266192877, 10.1266311039, 10.5453414387, 9.5468126086, 9.61580548008, 9.74096862304, 9.79812703688, 11.156250521, 10.3089526606, 8.98719682066, 10.3089526606, 10.203592145, 10.7579028807, 9.39266192877, 10.0858091093, 9.47270463644, 11.2897819137, 8.51719319142, 10.1266311039, 10.2399597892, 8.98719682066, 9.21034037198, 9.10497985632, 9.90348755254, 9.90348755254, 10.2399597892, 5.57972982599, 10.165851817, 10.203592145, 9.5468126086, 10.3734911818, 9.21034037198, 8.85366542804, 10.2399597892, 11.0020998412, 9.39266192877, 9.61580548008, 10.165851817, 10.165851817, 9.83734775003, 11.2897819137, 10.7789562899, 9.79812703688, 10.4631033405, 8.51719319142, 9.10497985632, 10.3089526606, 11.2897819137, 10.4631033405, 9.39266192877, 12.2060726455, 8.2940496401, 7.60090245954, 7.60090245954, 9.61580548008, 7.31322038709, 10.2399597892, 9.10497985632, 11.0020998412, 7.09007683578, 7.2442275156, 8.85366542804, 9.95227771671, 10.6919449129, 10.275051109, 8.00636756765, 9.39266192877, 9.90348755254, 10.5186731916, 8.98719682066, 10.4631033405, 10.1266311039, 9.79812703688, 10.3089526606, 9.39266192877, 9.79812703688, 9.90348755254, 10.3417424835, 8.69951474821, 9.39266192877, 9.47270463644, 10.165851817, 9.61580548008, 10.3089526606, 7.60090245954, 8.51719319142, 10.8780471925, 7.60090245954, 10.1266311039, 8.51719319142, 9.95227771671, 9.74096862304, 9.39266192877, 10.6454248973, 9.95227771671, 10.1266311039, 8.00636756765, 8.2940496401, 9.90348755254, 10.8589989976, 11.0020998412, 9.61580548008, 11.4075649493, 7.60090245954, 9.68034400122, 10.0858091093, 9.61580548008, 10.6454248973, 9.21034037198, 9.74096862304, 10.3089526606, 10.3734911818, 10.4912742174, 9.21034037198, 9.90348755254, 10.0858091093, 9.74096862304, 10.0432494949, 10.1266311039, 10.8197782844, 9.90348755254, 10.3089526606, 8.85366542804, 10.3089526606, 8.00636756765, 9.90348755254, 10.5966347331, 9.68034400122, 9.30565055178, 9.68034400122, 9.79812703688, 9.39266192877, 8.2940496401, 11.0020998412, 10.6689553947, 10.3417424835, 10.8197782844, 10.203592145, 10.3089526606, 9.39266192877, 9.90348755254, 10.1266311039, 8.00636756765, 11.6082356448, 10.9681982895, 9.21034037198, 9.85219425815, 8.98719682066, 11.0020998412, 8.69951474821], dtype=np.float32).reshape(1059,1)
y=torch.tensor(y)
x= np.array([74.0, 66.0, 64.0, 63.0, 64.0, 62.0, 73.0, 72.0, 72.0, 68.0, 68.0, 65.0, 66.0, 68.0, 68.0, 70.0, 64.0, 73.0, 62.0, 63.0, 67.0, 66.0, 72.0, 63.0, 64.0, 72.0, 77.0, 64.0, 64.0, 72.0, 68.0, 64.0, 67.0, 65.0, 64.0, 65.0, 65.0, 67.0, 68.0, 60.0, 65.0, 62.0, 72.0, 67.0, 70.0, 68.0, 71.0, 71.0, 73.0, 68.0, 66.0, 69.0, 63.0, 62.0, 64.0, 67.0, 71.0, 60.0, 66.0, 66.0, 65.0, 70.0, 62.0, 72.0, 67.0, 68.0, 70.0, 62.0, 63.0, 66.0, 70.0, 68.0, 70.0, 66.0, 68.0, 70.0, 61.0, 64.0, 69.0, 64.0, 67.0, 69.0, 67.0, 68.0, 63.0, 71.0, 64.0, 68.0, 68.0, 66.0, 77.0, 67.0, 62.0, 67.0, 61.0, 64.0, 62.0, 63.0, 68.0, 64.0, 72.0, 64.0, 61.0, 74.0, 70.0, 71.0, 63.0, 64.0, 62.0, 70.0, 71.0, 71.0, 67.0, 64.0, 67.0, 62.0, 68.0, 62.0, 68.0, 74.0, 68.0, 62.0, 66.0, 68.0, 60.0, 68.0, 72.0, 66.0, 68.0, 68.0, 69.0, 64.0, 65.0, 61.0, 72.0, 66.0, 68.0, 70.0, 71.0, 71.0, 68.0, 60.0, 63.0, 68.0, 64.0, 68.0, 61.0, 68.0, 66.0, 70.0, 71.0, 65.0, 66.0, 70.0, 66.0, 61.0, 72.0, 74.0, 67.0, 66.0, 62.0, 72.0, 65.0, 60.0, 62.0, 66.0, 64.0, 65.0, 73.0, 69.0, 64.0, 67.0, 62.0, 63.0, 67.0, 68.0, 72.0, 70.0, 70.0, 67.0, 63.0, 66.0, 66.0, 71.0, 67.0, 76.0, 69.0, 65.0, 62.0, 62.0, 62.0, 61.0, 65.0, 72.0, 72.0, 64.0, 71.0, 72.0, 66.0, 65.0, 62.0, 66.0, 67.0, 64.0, 63.0, 67.0, 68.0, 64.0, 66.0, 65.0, 65.0, 72.0, 68.0, 74.0, 63.0, 64.0, 68.0, 67.0, 67.0, 73.0, 65.0, 77.0, 68.0, 62.0, 64.0, 67.0, 70.0, 62.0, 63.0, 62.0, 69.0, 64.0, 69.0, 59.0, 66.0, 62.0, 75.0, 63.0, 65.0, 70.0, 68.0, 69.0, 72.0, 64.0, 63.0, 73.0, 75.0, 65.0, 66.0, 66.0, 64.0, 66.0, 64.0, 63.0, 73.0, 72.0, 72.0, 64.0, 64.0, 68.0, 69.0, 60.0, 76.0, 72.0, 62.0, 62.0, 71.0, 74.0, 65.0, 63.0, 67.0, 63.0, 65.0, 65.0, 63.0, 70.0, 68.0, 67.0, 65.0, 69.0, 68.0, 66.0, 71.0, 64.0, 74.0, 62.0, 65.0, 66.0, 67.0, 73.0, 76.0, 63.0, 63.0, 70.0, 71.0, 65.0, 63.0, 64.0, 64.0, 67.0, 66.0, 68.0, 65.0, 67.0, 73.0, 63.0, 71.0, 73.0, 65.0, 59.0, 70.0, 72.0, 66.0, 70.0, 69.0, 68.0, 74.0, 67.0, 64.0, 67.0, 70.0, 64.0, 62.0, 68.0, 72.0, 63.0, 69.0, 64.0, 71.0, 64.0, 61.0, 68.0, 68.0, 64.0, 66.0, 62.0, 65.0, 66.0, 72.0, 70.0, 62.0, 71.0, 70.0, 64.0, 63.0, 65.0, 71.0, 62.0, 68.0, 76.0, 64.0, 66.0, 63.0, 63.0, 70.0, 68.0, 70.0, 69.0, 63.0, 65.0, 69.0, 68.0, 66.0, 65.0, 70.0, 70.0, 66.0, 68.0, 68.0, 70.0, 65.0, 64.0, 65.0, 77.0, 70.0, 64.0, 64.0, 64.0, 64.0, 63.0, 58.0, 62.0, 64.0, 64.0, 62.0, 64.0, 66.0, 69.0, 64.0, 71.0, 68.0, 68.0, 62.0, 63.0, 69.0, 67.0, 64.0, 70.0, 69.0, 69.0, 69.0, 60.0, 66.0, 67.0, 66.0, 70.0, 64.0, 60.0, 68.0, 73.0, 72.0, 64.0, 67.0, 71.0, 73.0, 70.0, 70.0, 71.0, 66.0, 75.0, 60.0, 72.0, 75.0, 60.0, 73.0, 65.0, 67.0, 69.0, 64.0, 70.0, 68.0, 62.0, 64.0, 68.0, 64.0, 73.0, 73.0, 69.0, 68.0, 71.0, 66.0, 66.0, 70.0, 66.0, 63.0, 75.0, 67.0, 63.0, 69.0, 71.0, 62.0, 65.0, 72.0, 65.0, 63.0, 64.0, 72.0, 64.0, 70.0, 65.0, 64.0, 64.0, 67.0, 73.0, 73.0, 65.0, 64.0, 67.0, 67.0, 74.0, 63.0, 74.0, 74.0, 63.0, 62.0, 62.0, 67.0, 69.0, 73.0, 63.0, 67.0, 69.0, 71.0, 72.0, 64.0, 64.0, 74.0, 62.0, 65.0, 60.0, 69.0, 61.0, 65.0, 66.0, 70.0, 72.0, 64.0, 71.0, 73.0, 64.0, 68.0, 64.0, 66.0, 67.0, 64.0, 64.0, 62.0, 69.0, 63.0, 72.0, 75.0, 70.0, 69.0, 64.0, 72.0, 69.0, 71.0, 59.0, 68.0, 77.0, 70.0, 69.0, 63.0, 73.0, 66.0, 72.0, 72.0, 69.0, 67.0, 66.0, 67.0, 68.0, 65.0, 62.0, 69.0, 70.0, 66.0, 66.0, 66.0, 72.0, 69.0, 66.0, 69.0, 60.0, 65.0, 62.0, 67.0, 67.0, 68.0, 66.0, 74.0, 65.0, 68.0, 66.0, 65.0, 62.0, 73.0, 62.0, 70.0, 58.0, 68.0, 67.0, 70.0, 63.0, 66.0, 65.0, 61.0, 61.0, 67.0, 73.0, 71.0, 64.0, 67.0, 62.0, 67.0, 69.0, 66.0, 66.0, 66.0, 66.0, 72.0, 64.0, 65.0, 72.0, 71.0, 64.0, 64.0, 67.0, 75.0, 66.0, 67.0, 71.0, 68.0, 67.0, 71.0, 63.0, 61.0, 65.0, 67.0, 65.0, 66.0, 67.0, 74.0, 74.0, 66.0, 69.0, 66.0, 74.0, 72.0, 66.0, 67.0, 65.0, 65.0, 68.0, 64.0, 64.0, 63.0, 69.0, 67.0, 60.0, 62.0, 72.0, 67.0, 66.0, 66.0, 60.0, 65.0, 72.0, 64.0, 64.0, 64.0, 66.0, 73.0, 74.0, 65.0, 63.0, 63.0, 66.0, 70.0, 66.0, 63.0, 63.0, 69.0, 73.0, 68.0, 64.0, 63.0, 70.0, 64.0, 66.0, 72.0, 64.0, 67.0, 66.0, 71.0, 71.0, 71.0, 74.0, 75.0, 72.0, 66.0, 65.0, 72.0, 60.0, 64.0, 65.0, 65.0, 62.0, 73.0, 68.0, 66.0, 71.0, 73.0, 61.0, 63.0, 64.0, 67.0, 63.0, 73.0, 66.0, 70.0, 68.0, 67.0, 74.0, 64.0, 60.0, 59.0, 75.0, 64.0, 71.0, 63.0, 67.0, 69.0, 70.0, 66.0, 74.0, 65.0, 64.0, 68.0, 66.0, 69.0, 60.0, 75.0, 64.0, 63.0, 64.0, 63.0, 67.0, 66.0, 65.0, 63.0, 66.0, 64.0, 71.0, 71.0, 72.0, 70.0, 74.0, 68.0, 74.0, 75.0, 68.0, 63.0, 72.0, 64.0, 63.0, 66.0, 61.0, 73.0, 65.0, 62.0, 68.0, 68.0, 63.0, 63.0, 68.0, 64.0, 70.0, 70.0, 72.0, 69.0, 63.0, 63.0, 63.0, 73.0, 69.0, 70.0, 65.0, 72.0, 62.0, 72.0, 73.0, 68.0, 66.0, 60.0, 65.0, 63.0, 64.0, 71.0, 67.0, 63.0, 65.0, 63.0, 65.0, 74.0, 67.0, 68.0, 65.0, 64.0, 68.0, 65.0, 72.0, 66.0, 64.0, 72.0, 64.0, 67.0, 68.0, 64.0, 66.0, 65.0, 70.0, 70.0, 66.0, 66.0, 74.0, 62.0, 66.0, 65.0, 71.0, 66.0, 67.0, 61.0, 66.0, 72.0, 69.0, 64.0, 63.0, 60.0, 70.0, 73.0, 65.0, 64.0, 72.0, 67.0, 69.0, 71.0, 66.0, 63.0, 71.0, 72.0, 68.0, 72.0, 66.0, 66.0, 65.0, 71.0, 74.0, 70.0, 64.0, 69.0, 63.0, 68.0, 73.0, 63.0, 71.0, 65.0, 65.0, 71.0, 70.0, 68.0, 66.0, 64.0, 66.0, 70.0, 64.0, 71.0, 64.0, 63.0, 66.0, 68.0, 62.0, 69.0, 64.0, 64.0, 69.0, 74.0, 68.0, 67.0, 72.0, 73.0, 64.0, 68.0, 63.0, 71.0, 64.0, 60.0, 66.0, 59.0, 63.0, 66.0, 65.0, 64.0, 66.0, 66.0, 73.0, 72.0, 74.0, 65.0, 71.0, 68.0, 70.0, 64.0, 59.0, 68.0, 68.0, 69.0, 69.0, 75.0, 69.0, 72.0, 68.0, 72.0, 63.0, 69.0, 63.0, 72.0, 65.0, 73.0, 69.0, 69.0, 61.0, 73.0, 67.0, 63.0, 62.0, 65.0, 72.0, 67.0, 65.0, 72.0, 64.0, 68.0, 68.0, 76.0, 63.0, 68.0, 72.0, 64.0, 68.0, 61.0, 67.0, 63.0, 60.0, 74.0, 62.0, 72.0, 65.0, 62.0, 71.0, 71.0, 70.0, 67.0, 62.0, 63.0, 61.0, 72.0, 63.0, 66.0, 64.0, 66.0, 68.0, 60.0, 61.0, 64.0, 66.0, 66.0, 67.0, 68.0, 66.0, 69.0, 69.0, 71.0, 74.0, 69.0, 72.0, 64.0, 72.0, 63.0, 70.0, 66.0, 62.0, 64.0, 69.0, 64.0, 67.0, 72.0, 65.0, 63.0, 70.0, 64.0, 68.0, 66.0, 70.0, 66.0, 64.0, 70.0, 74.0, 66.0, 62.0, 66.0, 62.0, 69.0, 68.0, 72.0, 64.0, 72.0, 74.0, 66.0, 68.0, 62.0, 71.0, 63.0, 71.0, 72.0, 72.0, 68.0, 64.0, 70.0, 66.0, 67.0, 68.0, 64.0, 65.0, 70.0, 71.0, 62.0, 71.0, 74.0, 64.0, 70.0, 64.0, 70.0, 74.0, 74.0, 66.0, 71.0, 69.0, 60.0, 64.0, 64.0, 72.0, 69.0, 67.0, 65.0, 68.0, 74.0, 65.0, 71.0, 64.0, 69.0, 64.0, 72.0, 63.0, 65.0, 72.0, 65.0, 64.0, 71.0, 62.0, 66.0, 64.0, 68.0, 66.0, 66.0, 66.0, 66.0, 63.0, 68.0, 70.0, 63.0, 70.0, 72.0, 75.0, 62.0, 68.0, 68.0, 70.0, 73.0, 62.0, 64.0, 73.0, 66.0, 70.0, 70.0, 72.0, 64.0, 72.0, 68.0], dtype=np.float32).reshape(1059,1)
x=torch.tensor(x)
eth= np.array([3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 3, 4, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 4, 3, 3, 3, 3, 1, 1, 4, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 1, 1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1, 1, 1, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 2, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 1, 3, 3, 1, 1, 4, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 1, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 4, 3, 1, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 1, 2, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 4, 1, 1, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 1, 3, 3, 3, 3, 3, 1, 1, 3, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 1, 3, 2, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 2, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 1, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 1, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 2, 3, 4, 3, 3, 4, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 3, 3, 4, 1, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 2, 1, 2, 3, 4, 2, 4, 3, 1, 2, 3, 1, 3, 2, 3, 3, 3, 1, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 4, 2, 4, 3, 3, 3, 3, 3, 3], dtype=np.int64).reshape(1059,1)
eth=torch.tensor(eth)
def model(n_eth,age,N,n_age,y,x,eth):
    c = torch.zeros([amb(n_eth),amb(n_age)])
    d = torch.zeros([amb(n_eth),amb(n_age)])
    sigma_b2 = pyro.sample('sigma_b2'.format(''), dist.Normal(torch.tensor(1234.0)*torch.ones([amb(1)]),torch.tensor(1234.0)*torch.ones([amb(1)])))
    sigma_b1 = pyro.sample('sigma_b1'.format(''), dist.Normal(torch.tensor(1234.0)*torch.ones([amb(1)]),torch.tensor(1234.0)*torch.ones([amb(1)])))
    sigma_a2 = pyro.sample('sigma_a2'.format(''), dist.Normal(torch.tensor(1234.0)*torch.ones([amb(1)]),torch.tensor(1234.0)*torch.ones([amb(1)])))
    sigma_a1 = pyro.sample('sigma_a1'.format(''), dist.Normal(torch.tensor(1234.0)*torch.ones([amb(1)]),torch.tensor(1234.0)*torch.ones([amb(1)])))
    sigma_c = pyro.sample('sigma_c'.format(''), dist.Normal(torch.tensor(1234.0)*torch.ones([amb(1)]),torch.tensor(1234.0)*torch.ones([amb(1)])))
    sigma_y = pyro.sample('sigma_y'.format(''), dist.Normal(torch.tensor(1234.0)*torch.ones([amb(1)]),torch.tensor(1234.0)*torch.ones([amb(1)])))
    sigma_d = pyro.sample('sigma_d'.format(''), dist.Normal(torch.tensor(1234.0)*torch.ones([amb(1)]),torch.tensor(1234.0)*torch.ones([amb(1)])))
    mu_a1 = pyro.sample('mu_a1'.format(''), dist.Normal(torch.tensor(0.0)*torch.ones([amb(1)]),torch.tensor(1.0)*torch.ones([amb(1)])))
    mu_a2 = pyro.sample('mu_a2'.format(''), dist.Normal(torch.tensor(0.0)*torch.ones([amb(1)]),torch.tensor(1.0)*torch.ones([amb(1)])))
    with pyro.iarange('a1_range_'.format('')):
        a1 = pyro.sample('a1'.format(''), dist.Normal(10*mu_a1*torch.ones([amb(n_eth)]),sigma_a1*torch.ones([amb(n_eth)])))
    with pyro.iarange('a2_range_'.format('')):
        a2 = pyro.sample('a2'.format(''), dist.Normal(mu_a2*torch.ones([amb(n_eth)]),sigma_a2*torch.ones([amb(n_eth)])))
    mu_b1 = pyro.sample('mu_b1'.format(''), dist.Normal(torch.tensor(0.0)*torch.ones([amb(1)]),torch.tensor(1.0)*torch.ones([amb(1)])))
    mu_b2 = pyro.sample('mu_b2'.format(''), dist.Normal(torch.tensor(0.0)*torch.ones([amb(1)]),torch.tensor(1.0)*torch.ones([amb(1)])))
    with pyro.iarange('b1_range_'.format('')):
        b1 = pyro.sample('b1'.format(''), dist.Normal(10*mu_b1*torch.ones([amb(n_age)]),sigma_b1*torch.ones([amb(n_age)])))
    with pyro.iarange('b2_range_'.format('')):
        b2 = pyro.sample('b2'.format(''), dist.Normal(0.1*mu_b2*torch.ones([amb(n_age)]),sigma_b2*torch.ones([amb(n_age)])))
    mu_c = pyro.sample('mu_c'.format(''), dist.Normal(torch.tensor(0.0)*torch.ones([amb(1)]),torch.tensor(1.0)*torch.ones([amb(1)])))
    for i in range(1, n_eth+1):
        with pyro.iarange('c_range_{0}'.format(i)):
            c[i-1] = pyro.sample('c{0}'.format(i-1), dist.Normal(10*mu_c*torch.ones([amb(n_age)]),sigma_c*torch.ones([amb(n_age)])))
    mu_d = pyro.sample('mu_d'.format(''), dist.Normal(torch.tensor(0.0)*torch.ones([amb(1)]),torch.tensor(1.0)*torch.ones([amb(1)])))
    for i in range(1, n_eth+1):
        with pyro.iarange('d_range_{0}'.format(i)):
            d[i-1] = pyro.sample('d{0}'.format(i-1), dist.Normal(0.1*mu_d*torch.ones([amb(n_age)]),sigma_d*torch.ones([amb(n_age)])))
    y_hat = torch.zeros([amb(N)])
    for i in range(1, N+1):
        y_hat[i-1]=a1[eth[i-1]-1]+a2[eth[i-1]-1]*x[i-1]+b1[age[i-1]-1]+b2[age[i-1]-1]*x[i-1]+c[eth[i-1]-1,age[i-1]-1]+d[eth[i-1]-1,age[i-1]-1]*x[i-1]
    pyro.sample('obs__100'.format(), dist.Normal(y_hat,sigma_y), obs=y)
    
def guide(n_eth,age,N,n_age,y,x,eth):
    c = torch.zeros([amb(n_eth),amb(n_age)])
    d = torch.zeros([amb(n_eth),amb(n_age)])
    arg_1 = pyro.param('arg_1', torch.ones((amb(1))))
    arg_2 = pyro.param('arg_2', torch.ones((amb(1))), constraint=constraints.positive)
    sigma_b2 = pyro.sample('sigma_b2'.format(''), dist.Cauchy(arg_1,arg_2))
    arg_3 = pyro.param('arg_3', torch.ones((amb(1))), constraint=constraints.positive)
    arg_4 = pyro.param('arg_4', torch.ones((amb(1))), constraint=constraints.positive)
    sigma_b1 = pyro.sample('sigma_b1'.format(''), dist.Gamma(arg_3,arg_4))
    arg_5 = pyro.param('arg_5', torch.ones((amb(1))), constraint=constraints.positive)
    arg_6 = pyro.param('arg_6', torch.ones((amb(1))), constraint=constraints.positive)
    sigma_a2 = pyro.sample('sigma_a2'.format(''), dist.Beta(arg_5,arg_6))
    arg_7 = pyro.param('arg_7', torch.ones((amb(1))), constraint=constraints.positive)
    sigma_a1 = pyro.sample('sigma_a1'.format(''), dist.Exponential(arg_7))
    arg_8 = pyro.param('arg_8', torch.ones((amb(1))), constraint=constraints.positive)
    arg_9 = pyro.param('arg_9', torch.ones((amb(1))), constraint=constraints.positive)
    sigma_c = pyro.sample('sigma_c'.format(''), dist.Pareto(arg_8,arg_9))
    arg_10 = pyro.param('arg_10', torch.ones((amb(1))), constraint=constraints.positive)
    arg_11 = pyro.param('arg_11', torch.ones((amb(1))), constraint=constraints.positive)
    sigma_y = pyro.sample('sigma_y'.format(''), dist.Gamma(arg_10,arg_11))
    arg_12 = pyro.param('arg_12', torch.ones((amb(1))), constraint=constraints.positive)
    arg_13 = pyro.param('arg_13', torch.ones((amb(1))), constraint=constraints.positive)
    sigma_d = pyro.sample('sigma_d'.format(''), dist.Beta(arg_12,arg_13))
    arg_14 = pyro.param('arg_14', torch.ones((amb(1))), constraint=constraints.positive)
    arg_15 = pyro.param('arg_15', torch.ones((amb(1))), constraint=constraints.positive)
    mu_a1 = pyro.sample('mu_a1'.format(''), dist.Gamma(arg_14,arg_15))
    arg_16 = pyro.param('arg_16', torch.ones((amb(1))), constraint=constraints.positive)
    mu_a2 = pyro.sample('mu_a2'.format(''), dist.Exponential(arg_16))
    arg_17 = pyro.param('arg_17', torch.ones((amb(n_eth))), constraint=constraints.positive)
    arg_18 = pyro.param('arg_18', torch.ones((amb(n_eth))), constraint=constraints.positive)
    with pyro.iarange('a1_prange'):
        a1 = pyro.sample('a1'.format(''), dist.Gamma(arg_17,arg_18))
    arg_19 = pyro.param('arg_19', torch.ones((amb(n_eth))), constraint=constraints.positive)
    with pyro.iarange('a2_prange'):
        a2 = pyro.sample('a2'.format(''), dist.Exponential(arg_19))
    arg_20 = pyro.param('arg_20', torch.ones((amb(1))))
    arg_21 = pyro.param('arg_21', torch.ones((amb(1))), constraint=constraints.positive)
    mu_b1 = pyro.sample('mu_b1'.format(''), dist.Cauchy(arg_20,arg_21))
    arg_22 = pyro.param('arg_22', torch.ones((amb(1))))
    arg_23 = pyro.param('arg_23', torch.ones((amb(1))), constraint=constraints.positive)
    mu_b2 = pyro.sample('mu_b2'.format(''), dist.Normal(arg_22,arg_23))
    arg_24 = pyro.param('arg_24', torch.ones((amb(n_age))))
    arg_25 = pyro.param('arg_25', torch.ones((amb(n_age))), constraint=constraints.positive)
    with pyro.iarange('b1_prange'):
        b1 = pyro.sample('b1'.format(''), dist.Cauchy(arg_24,arg_25))
    arg_26 = pyro.param('arg_26', torch.ones((amb(n_age))), constraint=constraints.positive)
    arg_27 = pyro.param('arg_27', torch.ones((amb(n_age))), constraint=constraints.positive)
    with pyro.iarange('b2_prange'):
        b2 = pyro.sample('b2'.format(''), dist.Pareto(arg_26,arg_27))
    arg_28 = pyro.param('arg_28', torch.ones((amb(1))), constraint=constraints.positive)
    arg_29 = pyro.param('arg_29', torch.ones((amb(1))), constraint=constraints.positive)
    mu_c = pyro.sample('mu_c'.format(''), dist.Weibull(arg_28,arg_29))
    for i in range(1, n_eth+1):
        arg_30 = pyro.param('arg_30', torch.ones((amb(n_age))))
        arg_31 = pyro.param('arg_31', torch.ones((amb(n_age))), constraint=constraints.positive)
        with pyro.iarange('c_prange'):
            c[i-1] = pyro.sample('c{0}'.format(i-1), dist.Normal(arg_30,arg_31))
        pass
    arg_32 = pyro.param('arg_32', torch.ones((amb(1))), constraint=constraints.positive)
    arg_33 = pyro.param('arg_33', torch.ones((amb(1))))
    arg_34 = pyro.param('arg_34', torch.ones((amb(1))), constraint=constraints.positive)
    mu_d = pyro.sample('mu_d'.format(''), dist.StudentT(df=arg_32,loc=arg_33,scale=arg_34))
    for i in range(1, n_eth+1):
        arg_35 = pyro.param('arg_35', torch.ones((amb(n_age))), constraint=constraints.positive)
        arg_36 = pyro.param('arg_36', torch.ones((amb(n_age))), constraint=constraints.positive)
        with pyro.iarange('d_prange'):
            d[i-1] = pyro.sample('d{0}'.format(i-1), dist.Gamma(arg_35,arg_36))
        pass
    for i in range(1, N+1):
        pass
    
    pass
    return { "sigma_b2": sigma_b2,"sigma_y": sigma_y,"sigma_b1": sigma_b1,"d": d,"mu_c": mu_c,"c": c,"sigma_a2": sigma_a2,"sigma_a1": sigma_a1,"a1": a1,"a2": a2,"b1": b1,"b2": b2,"sigma_c": sigma_c,"mu_a2": mu_a2,"mu_a1": mu_a1,"mu_b1": mu_b1,"mu_b2": mu_b2,"mu_d": mu_d,"sigma_d": sigma_d, }
optim = Adam({'lr': 0.05})
svi = SVI(model, guide, optim, loss=Trace_ELBO() if pyro.__version__ > '0.1.2' else 'ELBO')
for i in range(4000):
    loss = svi.step(n_eth,age,N,n_age,y,x,eth)
    if ((i % 1000) == 0):
        print(loss)
for name in pyro.get_param_store().get_all_param_names():
    print(('{0} : {1}'.format(name, pyro.param(name).data.numpy())))
print('sigma_b2_mean', np.array2string(dist.Cauchy(pyro.param('arg_1'), pyro.param('arg_2')).mean.detach().numpy(), separator=','))
print('c_mean', np.array2string(dist.Normal(pyro.param('arg_30'), pyro.param('arg_31')).mean.detach().numpy(), separator=','))
print('sigma_b1_mean', np.array2string(dist.Gamma(pyro.param('arg_3'), pyro.param('arg_4')).mean.detach().numpy(), separator=','))
print('d_mean', np.array2string(dist.Gamma(pyro.param('arg_35'), pyro.param('arg_36')).mean.detach().numpy(), separator=','))
print('mu_b2_mean', np.array2string(dist.Normal(pyro.param('arg_22'), pyro.param('arg_23')).mean.detach().numpy(), separator=','))
print('sigma_a2_mean', np.array2string(dist.Beta(pyro.param('arg_5'), pyro.param('arg_6')).mean.detach().numpy(), separator=','))
print('sigma_a1_mean', np.array2string(dist.Exponential(pyro.param('arg_7')).mean.detach().numpy(), separator=','))
print('a1_mean', np.array2string(dist.Gamma(pyro.param('arg_17'), pyro.param('arg_18')).mean.detach().numpy(), separator=','))
print('mu_b1_mean', np.array2string(dist.Cauchy(pyro.param('arg_20'), pyro.param('arg_21')).mean.detach().numpy(), separator=','))
print('a2_mean', np.array2string(dist.Exponential(pyro.param('arg_19')).mean.detach().numpy(), separator=','))
print('b1_mean', np.array2string(dist.Cauchy(pyro.param('arg_24'), pyro.param('arg_25')).mean.detach().numpy(), separator=','))
print('b2_mean', np.array2string(dist.Pareto(pyro.param('arg_26'), pyro.param('arg_27')).mean.detach().numpy(), separator=','))
print('sigma_c_mean', np.array2string(dist.Pareto(pyro.param('arg_8'), pyro.param('arg_9')).mean.detach().numpy(), separator=','))
print('mu_a2_mean', np.array2string(dist.Exponential(pyro.param('arg_16')).mean.detach().numpy(), separator=','))
print('mu_a1_mean', np.array2string(dist.Gamma(pyro.param('arg_14'), pyro.param('arg_15')).mean.detach().numpy(), separator=','))
print('mu_d_mean', np.array2string(dist.StudentT(pyro.param('arg_32')).mean.detach().numpy(), separator=','))
print('mu_c_mean', np.array2string(dist.Weibull(pyro.param('arg_28'), pyro.param('arg_29')).mean.detach().numpy(), separator=','))
print('sigma_y_mean', np.array2string(dist.Gamma(pyro.param('arg_10'), pyro.param('arg_11')).mean.detach().numpy(), separator=','))
print('sigma_d_mean', np.array2string(dist.Beta(pyro.param('arg_12'), pyro.param('arg_13')).mean.detach().numpy(), separator=','))
np.set_printoptions(threshold=np.inf)
with open('samples','w') as samplefile:
    samplefile.write('sigma_b2:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['sigma_b2'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('sigma_y:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['sigma_y'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('sigma_b1:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['sigma_b1'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('d:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['d'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('mu_c:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['mu_c'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('c:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['c'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('sigma_a2:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['sigma_a2'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('sigma_a1:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['sigma_a1'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('a1:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['a1'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('a2:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['a2'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('b1:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['b1'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('b2:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['b2'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('sigma_c:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['sigma_c'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('mu_a2:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['mu_a2'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('mu_a1:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['mu_a1'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('mu_b1:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['mu_b1'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('mu_b2:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['mu_b2'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('mu_d:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['mu_d'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
    samplefile.write('sigma_d:')
    samplefile.write(np.array2string(np.array([guide(n_eth,age,N,n_age,y,x,eth)['sigma_d'].data.numpy() for _ in range(1000)]), separator=',').replace('\n',''))
    samplefile.write('\n')
